{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1c2f55-658f-49d8-a484-de1cf23607ba",
   "metadata": {},
   "source": [
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625af24-8a45-49e3-a46a-053729addce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c005b3a-9182-4658-b096-915fb8439925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/z5173707/root/projects/FHS/venv/python3.12.6/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-21 22:35:32,648 - httpx - INFO - HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-10-21 22:35:32,660 - httpx - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 22:35:32,917 - httpx - INFO - HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "2024-10-21 22:35:32,984 - httpx - INFO - HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "2024-10-21 22:35:33,289 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "/Users/z5173707/root/projects/FHS/venv/python3.12.6/lib/python3.12/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n",
      "2024-10-21 22:35:55,168 - speechgrid - INFO - Loading ASR Model...\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "2024-10-21 22:35:58,953 - pyctcdecode.decoder - INFO - Using arpa instead of binary LM file, decoder instantiation might be slow.\n",
      "Reading /Users/z5173707/root/projects/speechgrid/Models/ASR/LM/ngram/4gram_big.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "2024-10-21 22:35:58,993 - pyctcdecode.alphabet - INFO - Alphabet determined to be of regular style.\n",
      "2024-10-21 22:35:58,993 - pyctcdecode.alphabet - INFO - Found '|' in vocabulary but not ' ', doing substitution.\n",
      "2024-10-21 22:35:58,994 - pyctcdecode.alphabet - INFO - Found <pad> in vocabulary, interpreted as a CTC blank token, substituting with .\n",
      "2024-10-21 22:35:58,994 - pyctcdecode.alphabet - INFO - Found <unk> in vocabulary, interpreting as unknown token, substituting with ⁇.\n",
      "2024-10-21 22:35:58,994 - pyctcdecode.alphabet - WARNING - Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "2024-10-21 22:35:59,683 - speechgrid - INFO - Loading SD Model...\n",
      "2024-10-21 22:35:59,900 - speechgrid - INFO - Loading VAD Model...\n",
      "2024-10-21 22:35:59,914 - speechgrid - INFO - Loading Speech File...\n",
      "2024-10-21 22:36:01,604 - speechgrid - INFO - Start processing, following tasks will be performed on taukdial-003-1 VAD,SD,ASR\n",
      "2024-10-21 22:36:01,604 - speechgrid - INFO - Applying VAD...\n",
      "2024-10-21 22:36:02,167 - speechgrid - INFO - Applying SD...\n",
      "/Users/z5173707/root/projects/FHS/venv/python3.12.6/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "2024-10-21 22:36:12,517 - speechgrid - INFO - Applying ASR...\n",
      "2024-10-21 22:36:24,497 - speechgrid - INFO - Saving output files in /Users/z5173707/root/projects/speechgrid/output, taukdial-003-1\n",
      "2024-10-21 22:36:24,502 - speechgrid - INFO - Processing taukdial-003-1 is completed\n",
      "/Users/z5173707/root/projects/FHS/venv/python3.12.6/lib/python3.12/site-packages/gradio/processing_utils.py:579: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n",
      "2024-10-21 22:37:07,912 - speechgrid - INFO - Loading Speech File...\n",
      "2024-10-21 22:37:07,925 - speechgrid - INFO - Start processing, following tasks will be performed on taukdial-002-3 ASR\n",
      "2024-10-21 22:37:07,926 - speechgrid - INFO - Applying ASR...\n",
      "2024-10-21 22:37:27,991 - speechgrid - INFO - Saving output files in /Users/z5173707/root/projects/speechgrid/output, taukdial-002-3\n",
      "2024-10-21 22:37:27,998 - speechgrid - INFO - Processing taukdial-002-3 is completed\n"
     ]
    }
   ],
   "source": [
    "##### HAVE AN ISSUE HERE WITH gr.State \n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "from speechgrid import SpeechGrid, SpeechGridInterface\n",
    "from config import setup_logger, output_dir\n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) == 2:\n",
    "    shareable=bool(int(sys.argv[1]))\n",
    "else:\n",
    "    shareable = False\n",
    "\n",
    "\n",
    "def init_speech_grid_interface(config_file='config.yaml'):\n",
    "    return SpeechGridInterface(config_file=config_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_gradio_interface(speech_grid_interface):\n",
    "\n",
    "    def reset_min_max(exact,min_v,max_v):\n",
    "        if exact > 0:\n",
    "            min_v = 0\n",
    "            max_v = 0\n",
    "        speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "        return exact, min_v, max_v\n",
    "\n",
    "    def validate_min_max(exact, min_v, max_v):\n",
    "        if min_v > 0 or max_v > 0:\n",
    "            exact = 0\n",
    "            if min_v > max_v:\n",
    "                max_v = min_v\n",
    "        speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "        return exact, min_v, max_v\n",
    "    \n",
    "    def audio_stat(audio_value):\n",
    "        if audio_value:\n",
    "            return gr.Button(\"Process Audio\", interactive=True)\n",
    "        else:\n",
    "            return gr.Button(\"Process Audio\", interactive=False)\n",
    "    \n",
    "    def audio_record():\n",
    "        speech_grid_interface.recorded_speech = True\n",
    "    \n",
    "    def audio_upload():\n",
    "        speech_grid_interface.recorded_speech = False\n",
    "    \n",
    "    def set_tasks(tasks):\n",
    "        speech_grid_interface.set_tasks(tasks)\n",
    "    \n",
    "    with gr.Blocks(title=\"SpeechGrid\", theme=gr.themes.Soft()) as gui:\n",
    "        \n",
    "        with gr.Tab('Main'):\n",
    "    \n",
    "            record_audio = gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\")\n",
    "            \n",
    "            \n",
    "        \n",
    "            tasks = gr.CheckboxGroup(choices=[(\"Speech to Text\",\"ASR\"),\n",
    "                                              (\"Speaker Separation\",\"SD\"),\n",
    "                                              (\"Speech Detection\",\"VAD\")],\n",
    "                                     value=speech_grid_interface.get_tasks(),\n",
    "                                     label=\"Tasks\",\n",
    "                                     info=\"Apply the following tasks:\")\n",
    "            tasks.input(set_tasks, inputs=tasks)\n",
    "                \n",
    "        \n",
    "            process = gr.Button(\"Process Audio\", interactive=False)\n",
    "    \n",
    "            record_audio.input(audio_stat, inputs=record_audio, outputs=process)\n",
    "            record_audio.stop_recording(audio_record)\n",
    "            record_audio.upload(audio_upload)\n",
    "        \n",
    "            output_text = gr.Textbox(label='Progress', interactive=False)\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    d1 = gr.DownloadButton(\"Download output\", visible=False)\n",
    "                with gr.Column():\n",
    "                    d2 = gr.DownloadButton(\"Download speech file\", visible=False)\n",
    "        \n",
    "            \n",
    "            \n",
    "        with gr.Tab('Advanced Options'):\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                ### Speaker Separation\n",
    "                Number of speakers\n",
    "                \"\"\")\n",
    "            with gr.Row():\n",
    "                n_exact = gr.Number(label='Exact')\n",
    "                n_min = gr.Number(label='Minimum')\n",
    "                n_max = gr.Number(label='Maximum')\n",
    "    \n",
    "                n_exact.input(reset_min_max,\n",
    "                               inputs=[n_exact, n_min, n_max],\n",
    "                              outputs=[n_exact, n_min, n_max])\n",
    "                n_min.input(validate_min_max,\n",
    "                            inputs=[n_exact, n_min, n_max],\n",
    "                            outputs=[n_exact, n_min, n_max])\n",
    "                n_max.input(validate_min_max,\n",
    "                            inputs=[n_exact, n_min, n_max],\n",
    "                            outputs=[n_exact, n_min, n_max])\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                ### Speech to Text\n",
    "                \"\"\"\n",
    "            )\n",
    "            with gr.Row():\n",
    "                avail_lang = [(k,v) for k,v in speech_grid_interface.get_asr_available_lang().items()]\n",
    "                lang_drop = gr.Dropdown(label='Language', choices=avail_lang, value=speech_grid_interface.get_asr_lang())\n",
    "                lang_drop.change(speech_grid_interface.set_asr_lang,\n",
    "                                inputs=lang_drop)\n",
    "    \n",
    "                is_lm_enabled = speech_grid_interface.get_lm_enable()\n",
    "                lm_enable = gr.Checkbox(label='Enable Language Model', value=is_lm_enabled, interactive=True)\n",
    "                lm_enable.change(speech_grid_interface.set_lm_enable,\n",
    "                                inputs=lm_enable)\n",
    "        \n",
    "        process.click(speech_grid_interface.process, \n",
    "                          inputs=record_audio,\n",
    "                          outputs=[output_text, d1, d2])\n",
    "         \n",
    "    gui.queue().launch(share=shareable)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    setup_logger()\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    \n",
    "    speech_grid_interface = init_speech_grid_interface(config_file='config.yaml')\n",
    "\n",
    "    create_gradio_interface(speech_grid_interface)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b7ce6-49b7-4c27-ae65-2cd44c3e9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "#TODO: Progress bar\n",
    "#TODO: VAD ########DONE\n",
    "#TODO: Number of speakers  ######DONE\n",
    "#TODO: Word alignment\n",
    "#TODO: Download button  ######DONE\n",
    "#TODO: Wrape in a docker #####DONE\n",
    "#TODO: Test pyannote offline  ########DONE\n",
    "#TODO: Logging of errors and info    #########IN PROGRESS\n",
    "#TODO: ASR with LM  ########DONE\n",
    "#TODO: Process batch\n",
    "#TODO: Kaldi ASR\n",
    "#TODO: MMS ASR   ######DONE\n",
    "#TODO: Add parameters selection for ASR, SD, VAD\n",
    "#TODO: Rewrite the textgrid\n",
    "#TODO: TextGrid code to get the logger and use logging instead of print.\n",
    "#TODO: Add logging to other packages\n",
    "#TODO: Use .bin instead of ARPA in LM\n",
    "#TODO: ASR add the expected words\n",
    "#TODO: Consider control the offset in interval ASR\n",
    "#TODO: Add parameters of min silence duration #NEED TO WELL UNDERSTAND THESE PARAMETERS\n",
    "#TODO: Create set, get for speaker number\n",
    "#TODO: Name of file as the uploaded file\n",
    "#TODO: Make process enable after loading or recording ####DONE####\n",
    "#TODO: Use import tempfile to access the temp dir if need to do so\n",
    "#TODO: Review the use of get and set, use @property instead or direct access\n",
    "#TODO: Add nemo diarization\n",
    "\n",
    "#TODO: May specify the min but max 0?!\n",
    "\n",
    "def reset_min_max(exact,min_v,max_v):\n",
    "    if exact > 0:\n",
    "        min_v = 0\n",
    "        max_v = 0\n",
    "    speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "    return exact, min_v, max_v\n",
    "\n",
    "def validate_min_max(exact, min_v, max_v):\n",
    "    if min_v > 0 or max_v > 0:\n",
    "        exact = 0\n",
    "        if min_v > max_v:\n",
    "            max_v = min_v\n",
    "    speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "    return exact, min_v, max_v\n",
    "\n",
    "def audio_stat(audio_value):\n",
    "    if audio_value:\n",
    "        return gr.Button(\"Process Audio\", interactive=True)\n",
    "    else:\n",
    "        return gr.Button(\"Process Audio\", interactive=False)\n",
    "\n",
    "def audio_record():\n",
    "    speech_grid_interface.recorded_speech = True\n",
    "\n",
    "def audio_upload():\n",
    "    speech_grid_interface.recorded_speech = False\n",
    "\n",
    "with gr.Blocks(title=\"SpeechGrid\", theme=gr.themes.Soft()) as gui:\n",
    "\n",
    "    with gr.Tab('Main'):\n",
    "\n",
    "        record_audio = gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\")\n",
    "        \n",
    "        \n",
    "    \n",
    "        tasks = gr.CheckboxGroup(choices=[(\"Speech to Text\",\"ASR\"),\n",
    "                                          (\"Speaker Separation\",\"SD\"),\n",
    "                                          (\"Speech Detection\",\"VAD\")],\n",
    "                                 value=speech_grid_interface.get_tasks(),\n",
    "                                 label=\"Tasks\",\n",
    "                                 info=\"Apply the following tasks:\")\n",
    "        tasks.input(speech_grid_interface.set_tasks, inputs=tasks)\n",
    "            \n",
    "    \n",
    "        process = gr.Button(\"Process Audio\", interactive=False)\n",
    "\n",
    "        record_audio.input(audio_stat, inputs=record_audio, outputs=process)\n",
    "        record_audio.stop_recording(audio_record)\n",
    "        record_audio.upload(audio_upload)\n",
    "    \n",
    "        output_text = gr.Textbox(label='Progress', interactive=False)\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                d1 = gr.DownloadButton(\"Download output\", visible=False)\n",
    "            with gr.Column():\n",
    "                d2 = gr.DownloadButton(\"Download speech file\", visible=False)\n",
    "    \n",
    "        \n",
    "        \n",
    "    with gr.Tab('Advanced Options'):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ### Speaker Separation\n",
    "            Number of speakers\n",
    "            \"\"\")\n",
    "        with gr.Row():\n",
    "            n_exact = gr.Number(label='Exact')\n",
    "            n_min = gr.Number(label='Minimum')\n",
    "            n_max = gr.Number(label='Maximum')\n",
    "\n",
    "            n_exact.input(reset_min_max,\n",
    "                           inputs=[n_exact, n_min, n_max],\n",
    "                          outputs=[n_exact, n_min, n_max])\n",
    "            n_min.input(validate_min_max,\n",
    "                        inputs=[n_exact, n_min, n_max],\n",
    "                        outputs=[n_exact, n_min, n_max])\n",
    "            n_max.input(validate_min_max,\n",
    "                        inputs=[n_exact, n_min, n_max],\n",
    "                        outputs=[n_exact, n_min, n_max])\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ### Speech to Text\n",
    "            \"\"\"\n",
    "        )\n",
    "        with gr.Row():\n",
    "            avail_lang = [(k,v) for k,v in speech_grid_interface.get_asr_available_lang().items()]\n",
    "            lang_drop = gr.Dropdown(label='Language', choices=avail_lang, value=speech_grid_interface.get_asr_lang())\n",
    "            lang_drop.change(speech_grid_interface.set_asr_lang,\n",
    "                            inputs=lang_drop)\n",
    "\n",
    "            is_lm_enabled = speech_grid_interface.get_lm_enable()\n",
    "            lm_enable = gr.Checkbox(label='Enable Language Model', value=is_lm_enabled, interactive=True)\n",
    "            lm_enable.change(speech_grid_interface.set_lm_enable,\n",
    "                            inputs=lm_enable)\n",
    "    \n",
    "    process.click(speech_grid_interface.process, \n",
    "                      inputs=record_audio,\n",
    "                      outputs=[output_text, d1, d2])\n",
    "     \n",
    "gui.queue().launch(share=shareable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7192d1a-b8cc-4d79-ae6f-a24766c93c54",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000803a1-5b8a-4ebb-856b-7d7c42e4e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import soundfile as sf\n",
    "import gradio as gr\n",
    "\n",
    "from speechgrid import SpeechGrid\n",
    "from config import setup_logger, output_dir\n",
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n",
    "\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SpeechGridInterface(SpeechGrid):\n",
    "    def __init__(self, config_file):\n",
    "        super().__init__(config_file=config_file)\n",
    "        #self.speech_grid = SpeechGrid(config_file=config_file)\n",
    "        self.tasks = []\n",
    "        #Options\n",
    "        self.recorded_speech = False #If user record file on the fly\n",
    "    \n",
    "        \n",
    "\n",
    "    def add_task(self, task):\n",
    "        if task not in self.tasks:\n",
    "            self.tasks.append(task)\n",
    "\n",
    "    def remove_task(self, task):\n",
    "        if task in self.tasks:\n",
    "            self.tasks.remove(task)\n",
    "\n",
    "    def set_tasks(self, tasks):\n",
    "        self.tasks = tasks\n",
    "        \n",
    "    def get_tasks(self):\n",
    "        return self.tasks\n",
    "\n",
    "\n",
    "    def process(self, path, mode='single', progress=gr.Progress()): #input either a speech file o\n",
    "        self.load_tasks(self.get_tasks())\n",
    "\n",
    "        if mode=='single':\n",
    "            speech_file, output_zip_file, wav_file_created, out_file_created = self.process_file(path, progress = progress)\n",
    "            if wav_file_created:\n",
    "                download_speech_enable = True\n",
    "                download_speech_value = speech_file\n",
    "                download_speech_label = f\"Download speech file\"\n",
    "            else:\n",
    "                download_speech_enable = False\n",
    "                download_speech_value = None\n",
    "                download_speech_label = \"Error in saving speech file\"\n",
    "                \n",
    "            if out_file_created:\n",
    "                download_data_enable = True\n",
    "                download_data_value = output_zip_file\n",
    "                download_data_label = f\"Download output file\"\n",
    "            else:\n",
    "                download_data_enable = False\n",
    "                download_data_value = None\n",
    "                download_data_label = \"Error in archiving data\"\n",
    "\n",
    "            return [\"Processing completed..\", \n",
    "                gr.DownloadButton(label=download_data_label,\n",
    "                                  value=download_data_value,\n",
    "                                  interactive=download_data_enable,\n",
    "                                  visible=True),\n",
    "                \n",
    "                gr.DownloadButton(label=download_speech_label,\n",
    "                                  value=download_speech_value,\n",
    "                                  interactive=download_speech_enable,\n",
    "                                  visible=True)]\n",
    "    \n",
    "    def apply_tasks_to_speech(self, task_pipeline, speech, basename, sr=16000, progress = gr.Progress()):\n",
    "        out_textgrid = []\n",
    "\n",
    "        num_processes = len(task_pipeline)+1\n",
    "        i = 1\n",
    "        for task in task_pipeline:\n",
    "            logger.info(f'Applying {task}...')\n",
    "            progress(i/(num_processes+1), desc=f\"Applying {task}\")\n",
    "            i += 1\n",
    "            if task == 'ASR':\n",
    "                asr_engine = self.loaded_tasks['ASR']\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_ASR.TextGrid')\n",
    "                if not out_textgrid:\n",
    "                    asr_engine.process_speech(speech)\n",
    "                else:\n",
    "                    input_textgrid = out_textgrid[-1]\n",
    "                    asr_engine.process_intervals(speech, input_textgrid, sr = sr, offset_sec=0, \n",
    "                                                 speech_label = self.speech_label)\n",
    "                \n",
    "                asr_engine.write_textgrid(textgrid_file)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "            \n",
    "            elif task == 'VAD':\n",
    "                vad_engine = self.loaded_tasks['VAD']\n",
    "                rttm_file = os.path.join(output_dir,f'{basename}_VAD.rttm')\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_VAD.TextGrid')\n",
    "                vad_engine.process_speech(speech,sr)\n",
    "                vad_engine.write_rttm(rttm_file)\n",
    "                vad_engine.write_textgrid(textgrid_file, speech_label=self.speech_label)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "            \n",
    "            elif task == 'SD':\n",
    "                sd_engine = self.loaded_tasks['SD']\n",
    "                rttm_file = os.path.join(output_dir,f'{basename}_SD.rttm')\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_SD.TextGrid')\n",
    "                n_exact_speakers, n_min_speakers, n_max_speakers = self.get_speaker_numbers()\n",
    "                sd_engine.process_speech(speech=speech,\n",
    "                                         sr=sr,\n",
    "                                         n_exact_speakers = n_exact_speakers,\n",
    "                                         n_min_speakers = n_min_speakers,\n",
    "                                         n_max_speakers = n_max_speakers)\n",
    "                sd_engine.write_rttm(rttm_file)\n",
    "                sd_engine.write_textgrid(textgrid_file, speech_label=self.speech_label)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "        \n",
    "        return out_textgrid\n",
    "    \n",
    "    def process_file(self, speech_file, progress=gr.Progress()):\n",
    "        if self.recorded_speech:\n",
    "            basename = generate_file_basename() #Generate random name\n",
    "        else:\n",
    "            basename = os.path.splitext(os.path.basename(speech_file))[0]\n",
    "\n",
    "        progress(0, desc=f\"Loading Speech File...\")\n",
    "        \n",
    "        logger.info('Loading Speech File...')\n",
    "    \n",
    "        try:\n",
    "            speech, sr, duration = load_speech_file(speech_file)\n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to load the speech file {speech_file}, {e}')\n",
    "            raise\n",
    "        \n",
    "        tasks = set(self.get_tasks())\n",
    "        \n",
    "        task_pipeline = self.create_task_pipeline(tasks, duration)\n",
    "    \n",
    "        logger.info(f'Start processing, following tasks will be performed on {basename} {','.join(task_pipeline)}')\n",
    "    \n",
    "        #Loading task engines\n",
    "        self.load_tasks(task_pipeline)\n",
    "        \n",
    "        out_textgrid = self.apply_tasks_to_speech(task_pipeline, speech, basename, sr, progress)\n",
    "        \n",
    "        output_zip_file = os.path.join(output_dir,f'{basename}_output.zip')\n",
    "        \n",
    "        progress(1, desc=f\"Generate output files\")\n",
    "    \n",
    "    \n",
    "        logger.info(f'Saving output files in {output_dir}, {basename}')\n",
    "    \n",
    "        #This save a version of the speech file with 16k, mono, 16bit\n",
    "        wav_file_created = True\n",
    "        out_file_created = True\n",
    "        try:\n",
    "            speech_file = os.path.join(output_dir,f'{basename}.wav')\n",
    "            sf.write(speech_file, speech, sr)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to save the speech file {speech_file}, {e}')\n",
    "            wav_file_created = False\n",
    "        \n",
    "        try:\n",
    "            p = zip_files(out_textgrid, output_zip_file)\n",
    "       \n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to create output archive in {output_zip_file}, {e}')\n",
    "            out_file_created = False\n",
    "      \n",
    "         \n",
    "        progress(1, desc=f\"Processing {basename} completed..\")\n",
    "    \n",
    "        logger.info(f'Processing {basename} is completed')\n",
    "\n",
    "        return (speech_file, output_zip_file, wav_file_created, out_file_created)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd4863-fe50-4026-ba69-cc1d8ef63f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid_interface = SpeechGridInterface(config_file='configh.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02dece-098a-4641-ae45-771c131c3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.splitext(os.path.basename('/en/stable/user_install.html'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b40d55-023b-4532-af00-baea9cb4ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "shareable = False\n",
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n",
    "import soundfile as sf\n",
    "#TODO: Progress bar\n",
    "#TODO: VAD ########DONE\n",
    "#TODO: Number of speakers  ######DONE\n",
    "#TODO: Word alignment\n",
    "#TODO: Download button  ######DONE\n",
    "#TODO: Wrape in a docker #####DONE\n",
    "#TODO: Test pyannote offline  ########DONE\n",
    "#TODO: Logging of errors and info    #########IN PROGRESS\n",
    "#TODO: ASR with LM  ########DONE\n",
    "#TODO: Process batch\n",
    "#TODO: Kaldi ASR\n",
    "#TODO: MMS ASR   ######DONE\n",
    "#TODO: Add parameters selection for ASR, SD, VAD\n",
    "#TODO: Rewrite the textgrid\n",
    "#TODO: TextGrid code to get the logger and use logging instead of print.\n",
    "#TODO: Add logging to other packages\n",
    "#TODO: Use .bin instead of ARPA in LM\n",
    "#TODO: ASR add the expected words\n",
    "#TODO: Consider control the offset in interval ASR\n",
    "#TODO: Add parameters of min silence duration #NEED TO WELL UNDERSTAND THESE PARAMETERS\n",
    "#TODO: Create set, get for speaker number\n",
    "#TODO: Name of file as the uploaded file\n",
    "#TODO: Make process enable after loading or recording ####DONE####\n",
    "#TODO: Use import tempfile to access the temp dir if need to do so\n",
    "#TODO: Review the use of get and set, use @property instead or direct access\n",
    "\n",
    "def reset_min_max(exact,min_v,max_v):\n",
    "    if exact > 0:\n",
    "        min_v = 0\n",
    "        max_v = 0\n",
    "    speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "    return exact, min_v, max_v\n",
    "\n",
    "def validate_min_max(exact, min_v, max_v):\n",
    "    if min_v > 0 or max_v > 0:\n",
    "        exact = 0\n",
    "        if min_v > max_v:\n",
    "            max_v = min_v\n",
    "    speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "    return exact, min_v, max_v\n",
    "\n",
    "def audio_stat(audio_value):\n",
    "    if audio_value:\n",
    "        print(audio_value)\n",
    "        return gr.Button(\"Process Audio\", interactive=True)\n",
    "    else:\n",
    "        return gr.Button(\"Process Audio\", interactive=False)\n",
    "\n",
    "def audio_record():\n",
    "    speech_grid_interface.recorded_speech = True\n",
    "\n",
    "def audio_upload():\n",
    "    speech_grid_interface.recorded_speech = False\n",
    "\n",
    "with gr.Blocks(title=\"SpeechGrid\", theme=gr.themes.Soft()) as gui:\n",
    "\n",
    "    with gr.Tab('Main'):\n",
    "\n",
    "        record_audio = gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\")\n",
    "        \n",
    "        \n",
    "    \n",
    "        tasks = gr.CheckboxGroup(choices=[(\"Speech to Text\",\"ASR\"),\n",
    "                                          (\"Speaker Separation\",\"SD\"),\n",
    "                                          (\"Speech Detection\",\"VAD\")],\n",
    "                                 value=speech_grid_interface.get_tasks(),\n",
    "                                 label=\"Tasks\",\n",
    "                                 info=\"Apply the following tasks:\")\n",
    "        tasks.input(speech_grid_interface.set_tasks, inputs=tasks)\n",
    "            \n",
    "    \n",
    "        process = gr.Button(\"Process Audio\", interactive=False)\n",
    "\n",
    "        record_audio.input(audio_stat, inputs=record_audio, outputs=process)\n",
    "        record_audio.stop_recording(audio_record)\n",
    "        record_audio.upload(audio_upload)\n",
    "    \n",
    "        output_text = gr.Textbox(label='Progress', interactive=False)\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                d1 = gr.DownloadButton(\"Download output\", visible=False)\n",
    "            with gr.Column():\n",
    "                d2 = gr.DownloadButton(\"Download speech file\", visible=False)\n",
    "    \n",
    "        \n",
    "        \n",
    "    with gr.Tab('Advanced Options'):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ### Speaker Separation\n",
    "            Number of speakers\n",
    "            \"\"\")\n",
    "        with gr.Row():\n",
    "            n_exact = gr.Number(label='Exact')\n",
    "            n_min = gr.Number(label='Minimum')\n",
    "            n_max = gr.Number(label='Maximum')\n",
    "\n",
    "            n_exact.input(reset_min_max,\n",
    "                           inputs=[n_exact, n_min, n_max],\n",
    "                          outputs=[n_exact, n_min, n_max])\n",
    "            n_min.input(validate_min_max,\n",
    "                        inputs=[n_exact, n_min, n_max],\n",
    "                        outputs=[n_exact, n_min, n_max])\n",
    "            n_max.input(validate_min_max,\n",
    "                        inputs=[n_exact, n_min, n_max],\n",
    "                        outputs=[n_exact, n_min, n_max])\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ### Speech to Text\n",
    "            \"\"\"\n",
    "        )\n",
    "        with gr.Row():\n",
    "            avail_lang = [(k,v) for k,v in speech_grid_interface.get_asr_available_lang().items()]\n",
    "            lang_drop = gr.Dropdown(label='Language', choices=avail_lang, value=speech_grid_interface.get_asr_lang())\n",
    "            lang_drop.change(speech_grid_interface.set_asr_lang,\n",
    "                            inputs=lang_drop)\n",
    "\n",
    "            is_lm_enabled = speech_grid_interface.get_lm_enable()\n",
    "            lm_enable = gr.Checkbox(label='Enable Language Model', value=is_lm_enabled, interactive=True)\n",
    "            lm_enable.change(speech_grid_interface.set_lm_enable,\n",
    "                            inputs=lm_enable)\n",
    "    \n",
    "    process.click(speech_grid_interface.process, \n",
    "                      inputs=record_audio,\n",
    "                      outputs=[output_text, d1, d2])\n",
    "     \n",
    "gui.queue().launch(share=shareable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6850897-52d5-4037-a505-90f112605102",
   "metadata": {},
   "source": [
    "# V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160df86-17e4-4764-8df3-7627398f5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import soundfile as sf\n",
    "import gradio as gr\n",
    "\n",
    "from speechgrid import SpeechGrid\n",
    "from config import setup_logger, output_dir\n",
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n",
    "\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SpeechGridInterface:\n",
    "    def __init__(self, config_file):\n",
    "        self.speech_grid = SpeechGrid(config_file=config_file)\n",
    "        self.tasks = []\n",
    "        #Options\n",
    "        \n",
    "\n",
    "    def add_task(self, task):\n",
    "        if task not in self.tasks:\n",
    "            self.tasks.append(task)\n",
    "\n",
    "    def remove_task(self, task):\n",
    "        if task in self.tasks:\n",
    "            self.tasks.remove(task)\n",
    "\n",
    "    def set_tasks(self, tasks):\n",
    "        self.tasks = tasks\n",
    "        \n",
    "    def get_tasks(self):\n",
    "        return self.tasks\n",
    "\n",
    "\n",
    "    def process(self, path, mode='single', progress=gr.Progress()): #input either a speech file o\n",
    "        self.speech_grid.load_tasks(self.get_tasks())\n",
    "\n",
    "        if mode=='single':\n",
    "            speech_file, output_zip_file, wav_file_created, out_file_created = self.process_file(path, progress = progress)\n",
    "            if wav_file_created:\n",
    "                download_speech_enable = True\n",
    "                download_speech_value = speech_file\n",
    "                download_speech_label = f\"Download speech file\"\n",
    "            else:\n",
    "                download_speech_enable = False\n",
    "                download_speech_value = None\n",
    "                download_speech_label = \"Error in saving speech file\"\n",
    "                \n",
    "            if out_file_created:\n",
    "                download_data_enable = True\n",
    "                download_data_value = output_zip_file\n",
    "                download_data_label = f\"Download output file\"\n",
    "            else:\n",
    "                download_data_enable = False\n",
    "                download_data_value = None\n",
    "                download_data_label = \"Error in archiving data\"\n",
    "\n",
    "            return [\"Processing completed..\", \n",
    "                gr.DownloadButton(label=download_data_label,\n",
    "                                  value=download_data_value,\n",
    "                                  interactive=download_data_enable,\n",
    "                                  visible=True),\n",
    "                \n",
    "                gr.DownloadButton(label=download_speech_label,\n",
    "                                  value=download_speech_value,\n",
    "                                  interactive=download_speech_enable,\n",
    "                                  visible=True)]\n",
    "    \n",
    "    def apply_tasks_to_speech(self, task_pipeline, speech, basename, sr=16000, progress = gr.Progress()):\n",
    "        out_textgrid = []\n",
    "\n",
    "        num_processes = len(task_pipeline)+1\n",
    "        i = 1\n",
    "        for task in task_pipeline:\n",
    "            logger.info(f'Applying {task}...')\n",
    "            progress(i/(num_processes+1), desc=f\"Applying {task}\")\n",
    "            i += 1\n",
    "            if task == 'ASR':\n",
    "                asr_engine = self.speech_grid.loaded_tasks['ASR']\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_ASR.TextGrid')\n",
    "                if not out_textgrid:\n",
    "                    asr_engine.process_speech(speech)\n",
    "                else:\n",
    "                    input_textgrid = out_textgrid[-1]\n",
    "                    asr_engine.process_intervals(speech, input_textgrid, sr = sr, offset_sec=0, \n",
    "                                                 speech_label = self.speech_grid.speech_label)\n",
    "                \n",
    "                asr_engine.write_textgrid(textgrid_file)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "            \n",
    "            elif task == 'VAD':\n",
    "                vad_engine = self.speech_grid.loaded_tasks['VAD']\n",
    "                rttm_file = os.path.join(output_dir,f'{basename}_VAD.rttm')\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_VAD.TextGrid')\n",
    "                vad_engine.process_speech(speech,sr)\n",
    "                vad_engine.write_rttm(rttm_file)\n",
    "                vad_engine.write_textgrid(textgrid_file, speech_label=self.speech_grid.speech_label)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "            \n",
    "            elif task == 'SD':\n",
    "                sd_engine = self.speech_grid.loaded_tasks['SD']\n",
    "                rttm_file = os.path.join(output_dir,f'{basename}_SD.rttm')\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_SD.TextGrid')\n",
    "                n_exact_speakers, n_min_speakers, n_max_speakers = self.speech_grid.get_speaker_numbers()\n",
    "                sd_engine.process_speech(speech=speech,\n",
    "                                         sr=sr,\n",
    "                                         n_exact_speakers = n_exact_speakers,\n",
    "                                         n_min_speakers = n_min_speakers,\n",
    "                                         n_max_speakers = n_max_speakers)\n",
    "                sd_engine.write_rttm(rttm_file)\n",
    "                sd_engine.write_textgrid(textgrid_file, speech_label=self.speech_grid.speech_label)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "        \n",
    "        return out_textgrid\n",
    "    \n",
    "    def process_file(self, speech_file, progress=gr.Progress()):\n",
    "        basename = generate_file_basename()\n",
    "\n",
    "        progress(0, desc=f\"Loading Speech File...\")\n",
    "        \n",
    "        logger.info('Loading Speech File...')\n",
    "    \n",
    "        try:\n",
    "            speech, sr, duration = load_speech_file(speech_file)\n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to load the speech file {speech_file}, {e}')\n",
    "            raise\n",
    "        \n",
    "        tasks = set(self.get_tasks())\n",
    "        \n",
    "        task_pipeline = self.speech_grid.create_task_pipeline(tasks, duration)\n",
    "    \n",
    "        logger.info(f'Start processing, following tasks will be performed on {basename}', ','.join(task_pipeline))\n",
    "    \n",
    "        #Loading task engines\n",
    "        self.speech_grid.load_tasks(task_pipeline)\n",
    "        \n",
    "        out_textgrid = self.apply_tasks_to_speech(task_pipeline, speech, basename, sr, progress)\n",
    "        \n",
    "        output_zip_file = os.path.join(output_dir,f'{basename}_output.zip')\n",
    "        \n",
    "        progress(1, desc=f\"Generate output files\")\n",
    "    \n",
    "    \n",
    "        logger.info(f'Saving output files in {output_dir}, {basename}')\n",
    "    \n",
    "        #This save a version of the speech file with 16k, mono, 16bit\n",
    "        wav_file_created = True\n",
    "        out_file_created = True\n",
    "        try:\n",
    "            speech_file = os.path.join(output_dir,f'{basename}.wav')\n",
    "            sf.write(speech_file, speech, sr)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to save the speech file {speech_file}, {e}')\n",
    "            wav_file_created = False\n",
    "        \n",
    "        try:\n",
    "            p = zip_files(out_textgrid, output_zip_file)\n",
    "       \n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to create output archive in {output_zip_file}, {e}')\n",
    "            out_file_created = False\n",
    "      \n",
    "         \n",
    "        progress(1, desc=f\"Processing {basename} completed..\")\n",
    "    \n",
    "        logger.info(f'Processing {basename} is completed')\n",
    "\n",
    "        return (speech_file, output_zip_file, wav_file_created, out_file_created)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9358ecd-df9b-47a4-b08d-e272b41c79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import soundfile as sf\n",
    "import gradio as gr\n",
    "\n",
    "from speechgrid import SpeechGrid\n",
    "from config import setup_logger, output_dir\n",
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n",
    "\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SpeechGridInterface(SpeechGrid):\n",
    "    def __init__(self, config_file):\n",
    "        super().__init__(config_file=config_file)\n",
    "        #self.speech_grid = SpeechGrid(config_file=config_file)\n",
    "        self.tasks = []\n",
    "        #Options\n",
    "        \n",
    "\n",
    "    def add_task(self, task):\n",
    "        if task not in self.tasks:\n",
    "            self.tasks.append(task)\n",
    "\n",
    "    def remove_task(self, task):\n",
    "        if task in self.tasks:\n",
    "            self.tasks.remove(task)\n",
    "\n",
    "    def set_tasks(self, tasks):\n",
    "        self.tasks = tasks\n",
    "        \n",
    "    def get_tasks(self):\n",
    "        return self.tasks\n",
    "\n",
    "\n",
    "    def process(self, path, mode='single', progress=gr.Progress()): #input either a speech file o\n",
    "        self.load_tasks(self.get_tasks())\n",
    "\n",
    "        if mode=='single':\n",
    "            speech_file, output_zip_file, wav_file_created, out_file_created = self.process_file(path, progress = progress)\n",
    "            if wav_file_created:\n",
    "                download_speech_enable = True\n",
    "                download_speech_value = speech_file\n",
    "                download_speech_label = f\"Download speech file\"\n",
    "            else:\n",
    "                download_speech_enable = False\n",
    "                download_speech_value = None\n",
    "                download_speech_label = \"Error in saving speech file\"\n",
    "                \n",
    "            if out_file_created:\n",
    "                download_data_enable = True\n",
    "                download_data_value = output_zip_file\n",
    "                download_data_label = f\"Download output file\"\n",
    "            else:\n",
    "                download_data_enable = False\n",
    "                download_data_value = None\n",
    "                download_data_label = \"Error in archiving data\"\n",
    "\n",
    "            return [\"Processing completed..\", \n",
    "                gr.DownloadButton(label=download_data_label,\n",
    "                                  value=download_data_value,\n",
    "                                  interactive=download_data_enable,\n",
    "                                  visible=True),\n",
    "                \n",
    "                gr.DownloadButton(label=download_speech_label,\n",
    "                                  value=download_speech_value,\n",
    "                                  interactive=download_speech_enable,\n",
    "                                  visible=True)]\n",
    "    \n",
    "    def apply_tasks_to_speech(self, task_pipeline, speech, basename, sr=16000, progress = gr.Progress()):\n",
    "        out_textgrid = []\n",
    "\n",
    "        num_processes = len(task_pipeline)+1\n",
    "        i = 1\n",
    "        for task in task_pipeline:\n",
    "            logger.info(f'Applying {task}...')\n",
    "            progress(i/(num_processes+1), desc=f\"Applying {task}\")\n",
    "            i += 1\n",
    "            if task == 'ASR':\n",
    "                asr_engine = self.loaded_tasks['ASR']\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_ASR.TextGrid')\n",
    "                if not out_textgrid:\n",
    "                    asr_engine.process_speech(speech)\n",
    "                else:\n",
    "                    input_textgrid = out_textgrid[-1]\n",
    "                    asr_engine.process_intervals(speech, input_textgrid, sr = sr, offset_sec=0, \n",
    "                                                 speech_label = self.speech_label)\n",
    "                \n",
    "                asr_engine.write_textgrid(textgrid_file)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "            \n",
    "            elif task == 'VAD':\n",
    "                vad_engine = self.loaded_tasks['VAD']\n",
    "                rttm_file = os.path.join(output_dir,f'{basename}_VAD.rttm')\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_VAD.TextGrid')\n",
    "                vad_engine.process_speech(speech,sr)\n",
    "                vad_engine.write_rttm(rttm_file)\n",
    "                vad_engine.write_textgrid(textgrid_file, speech_label=self.speech_label)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "            \n",
    "            elif task == 'SD':\n",
    "                sd_engine = self.loaded_tasks['SD']\n",
    "                rttm_file = os.path.join(output_dir,f'{basename}_SD.rttm')\n",
    "                textgrid_file = os.path.join(output_dir,f'{basename}_SD.TextGrid')\n",
    "                n_exact_speakers, n_min_speakers, n_max_speakers = self.get_speaker_numbers()\n",
    "                sd_engine.process_speech(speech=speech,\n",
    "                                         sr=sr,\n",
    "                                         n_exact_speakers = n_exact_speakers,\n",
    "                                         n_min_speakers = n_min_speakers,\n",
    "                                         n_max_speakers = n_max_speakers)\n",
    "                sd_engine.write_rttm(rttm_file)\n",
    "                sd_engine.write_textgrid(textgrid_file, speech_label=self.speech_label)\n",
    "                out_textgrid.append(textgrid_file)\n",
    "        \n",
    "        return out_textgrid\n",
    "    \n",
    "    def process_file(self, speech_file, progress=gr.Progress()):\n",
    "        basename = generate_file_basename()\n",
    "\n",
    "        progress(0, desc=f\"Loading Speech File...\")\n",
    "        \n",
    "        logger.info('Loading Speech File...')\n",
    "    \n",
    "        try:\n",
    "            speech, sr, duration = load_speech_file(speech_file)\n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to load the speech file {speech_file}, {e}')\n",
    "            raise\n",
    "        \n",
    "        tasks = set(self.get_tasks())\n",
    "        \n",
    "        task_pipeline = self.create_task_pipeline(tasks, duration)\n",
    "    \n",
    "        logger.info(f'Start processing, following tasks will be performed on {basename}', ','.join(task_pipeline))\n",
    "    \n",
    "        #Loading task engines\n",
    "        self.load_tasks(task_pipeline)\n",
    "        \n",
    "        out_textgrid = self.apply_tasks_to_speech(task_pipeline, speech, basename, sr, progress)\n",
    "        \n",
    "        output_zip_file = os.path.join(output_dir,f'{basename}_output.zip')\n",
    "        \n",
    "        progress(1, desc=f\"Generate output files\")\n",
    "    \n",
    "    \n",
    "        logger.info(f'Saving output files in {output_dir}, {basename}')\n",
    "    \n",
    "        #This save a version of the speech file with 16k, mono, 16bit\n",
    "        wav_file_created = True\n",
    "        out_file_created = True\n",
    "        try:\n",
    "            speech_file = os.path.join(output_dir,f'{basename}.wav')\n",
    "            sf.write(speech_file, speech, sr)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to save the speech file {speech_file}, {e}')\n",
    "            wav_file_created = False\n",
    "        \n",
    "        try:\n",
    "            p = zip_files(out_textgrid, output_zip_file)\n",
    "       \n",
    "        except Exception as e:\n",
    "            logger.exception(f'Failed to create output archive in {output_zip_file}, {e}')\n",
    "            out_file_created = False\n",
    "      \n",
    "         \n",
    "        progress(1, desc=f\"Processing {basename} completed..\")\n",
    "    \n",
    "        logger.info(f'Processing {basename} is completed')\n",
    "\n",
    "        return (speech_file, output_zip_file, wav_file_created, out_file_created)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caabf02-86d4-439f-8f02-06bb00b2624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('config.yaml', 'r') as f:\n",
    "    data = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d3054-4ee8-4397-a300-1e184b2b671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,v) for k,v in data['speechgrid']['speech_recognition']['avail_lang'].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa68f1-e4f2-4e61-b9aa-5234a0938382",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['speechgrid']['speech_recognition']['lang_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cad4a-93a6-45fc-93b4-a32571835669",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid = SpeechGrid(config_file='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de44f9-3385-4699-972c-fd660479584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid.load_asr()\n",
    "speech_grid.load_sd()\n",
    "speech_grid.load_vad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2be438-1ebd-41e0-841b-e88a0658fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import soundfile as sf\n",
    "import gradio as gr\n",
    "\n",
    "from speechgrid import SpeechGrid\n",
    "from config import setup_logger, output_dir\n",
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8fb51-ae63-4d21-a680-ca9caba4ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid = SpeechGrid(config_file='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f5515-e38c-445c-ba1e-957b22432c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from config import setup_logger\n",
    "import logging\n",
    "import os\n",
    "from config import output_dir\n",
    "\n",
    "setup_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "def process_file(speech_file, tasks=['SD', 'ASR'],\n",
    "                 n_exact_speakers = 0,\n",
    "                 n_min_speakers = 0,\n",
    "                 n_max_speakers = 0,\n",
    "                 progress=gr.Progress()):\n",
    "    \n",
    "    basename = generate_file_basename()\n",
    "    \n",
    "\n",
    "    progress(0, desc=f\"Loading Speech File...\")\n",
    "    \n",
    "    logger.info('Loading Speech File...')\n",
    "\n",
    "    try:\n",
    "        speech, sr, duration = load_speech_file(speech_file)\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to load the speech file {speech_file}, {e}')\n",
    "        raise\n",
    "    \n",
    "    tasks = set(tasks)\n",
    "\n",
    "    \n",
    "    \n",
    "    task_pipeline = speech_grid.create_task_pipeline(tasks, duration)\n",
    "\n",
    "    logger.info('Start processing, following tasks will be performed', ','.join(task_pipeline))\n",
    "\n",
    "    #Loading task engines\n",
    "    speech_grid.load_tasks(task_pipeline)\n",
    "    \n",
    "    out_textgrid = []\n",
    "\n",
    "\n",
    "    num_processes = len(task_pipeline)+1\n",
    "    \n",
    "    \n",
    "    i = 1\n",
    "    for task in task_pipeline:\n",
    "        logger.info(f'Applying {task}')\n",
    "        progress(i/(num_processes+1), desc=f\"Applying {task}\")\n",
    "        i += 1\n",
    "        if task == 'ASR':\n",
    "            asr_engine = speech_grid.loaded_tasks['ASR']\n",
    "            textgrid_file = os.path.join(output_dir,f'{basename}_ASR.TextGrid')\n",
    "            if not out_textgrid:\n",
    "                asr_engine.process_speech(speech)\n",
    "            else:\n",
    "                input_textgrid = out_textgrid[-1]\n",
    "                asr_engine.process_intervals(speech, input_textgrid, sr = sr, offset_sec=0, speech_label = speech_grid.speech_label)\n",
    "            \n",
    "            asr_engine.write_textgrid(textgrid_file)\n",
    "            out_textgrid.append(textgrid_file)\n",
    "        \n",
    "        elif task == 'VAD':\n",
    "            vad_engine = speech_grid.loaded_tasks['VAD']\n",
    "            rttm_file = os.path.join(output_dir,f'{basename}_VAD.rttm')\n",
    "            textgrid_file = os.path.join(output_dir,f'{basename}_VAD.TextGrid')\n",
    "            vad_engine.process_speech(speech,sr)\n",
    "            vad_engine.write_rttm(rttm_file)\n",
    "            vad_engine.write_textgrid(textgrid_file, speech_label=speech_grid.speech_label)\n",
    "            out_textgrid.append(textgrid_file)\n",
    "        \n",
    "        elif task == 'SD':\n",
    "            sd_engine = speech_grid.loaded_tasks['SD']\n",
    "            rttm_file = os.path.join(output_dir,f'{basename}_SD.rttm')\n",
    "            textgrid_file = os.path.join(output_dir,f'{basename}_SD.TextGrid')\n",
    "            \n",
    "            sd_engine.process_speech(speech=speech,\n",
    "                                     sr=sr,\n",
    "                                     n_exact_speakers = n_exact_speakers,\n",
    "                                     n_min_speakers = n_min_speakers,\n",
    "                                     n_max_speakers = n_max_speakers)\n",
    "            sd_engine.write_rttm(rttm_file)\n",
    "            sd_engine.write_textgrid(textgrid_file, speech_label=speech_grid.speech_label)\n",
    "            out_textgrid.append(textgrid_file)\n",
    "    \n",
    "    \n",
    "    output_zip_file = os.path.join(output_dir,f'{basename}_output.zip')\n",
    "    \n",
    "    progress(num_processes/(num_processes+1), desc=f\"Generate output files\")\n",
    "\n",
    "\n",
    "    logger.info(f'Saving output files in {output_dir}, {basename}')\n",
    "\n",
    "    #This save a version of the speech file with 16k, mono, 16bit\n",
    "    try:\n",
    "        speech_file = os.path.join(output_dir,f'{basename}.wav')\n",
    "        sf.write(speech_file, speech, sr)\n",
    "        download_speech_enable = True\n",
    "        download_speech_value = speech_file\n",
    "        download_speech_label = f\"Download speech file\"\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to save the speech file {speech_file}, {e}')\n",
    "        download_speech_enable = False\n",
    "        download_speech_value = None\n",
    "        download_speech_label = \"Error in saving speech file\"\n",
    "    \n",
    "    try:\n",
    "        p = zip_files(out_textgrid, output_zip_file)\n",
    "        download_data_enable = True\n",
    "        download_data_value = output_zip_file\n",
    "        download_data_label = f\"Download output file\"\n",
    "   \n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to create output archive in {output_zip_file}, {e}')\n",
    "        #Disable Download Data Button\n",
    "        download_data_enable = False\n",
    "        download_data_value = None\n",
    "        download_data_label = \"Error in archiving data\"\n",
    "        \n",
    "        \n",
    "     \n",
    "    progress(1, desc=\"Processing completed..\")\n",
    "\n",
    "    logger.info('Processing is completed')\n",
    "    \n",
    "    return [\"Processing completed..\", \n",
    "            gr.DownloadButton(label=download_data_label,\n",
    "                              value=download_data_value,\n",
    "                              interactive=download_data_enable,\n",
    "                              visible=True),\n",
    "            \n",
    "            gr.DownloadButton(label=download_speech_label,\n",
    "                              value=download_speech_value,\n",
    "                              interactive=download_speech_enable,\n",
    "                              visible=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0da621-fea8-4fa7-9e88-795b14174e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid_interface = SpeechGridInterface(config_file='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e81ff-c6d0-4a1e-8234-6aa0ac8ed0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid_interface.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64bfca-3d8b-4bde-8c51-36f0c8cf61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "shareable = False\n",
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n",
    "import soundfile as sf\n",
    "#TODO: Progress bar\n",
    "#TODO: VAD ########DONE\n",
    "#TODO: Number of speakers\n",
    "#TODO: Word alignment\n",
    "#TODO: Download button  ######DONE\n",
    "#TODO: Wrape in a docker #####DONE\n",
    "#TODO: Test pyannote offline  ########DONE\n",
    "#TODO: Logging of errors and info    #########IN PROGRESS\n",
    "#TODO: ASR with LM  ########DONE\n",
    "#TODO: Process batch\n",
    "#TODO: Kaldi ASR\n",
    "#TODO: MMS ASR\n",
    "#TODO: Add parameters selection for ASR, SD, VAD\n",
    "#TODO: Rewrite the textgrid\n",
    "#TODO: TextGrid code to get the logger and use logging instead of print.\n",
    "#TODO: Add logging to other packages\n",
    "#TODO: Use .bin instead of ARPA in LM\n",
    "#TODO: ASR add the expected words\n",
    "#TODO: Consider control the offset in interval ASR\n",
    "#TODO: Add parameters of min silence duration #NEED TO WELL UNDERSTAND THESE PARAMETERS\n",
    "#TODO: Create set, get for speaker number\n",
    "#TODO: Name of file as the uploaded file\n",
    "#TODO: Make process enable after loading or recording\n",
    "\n",
    "def reset_min_max(exact,min_v,max_v):\n",
    "    if exact > 0:\n",
    "        min_v = 0\n",
    "        max_v = 0\n",
    "    speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "    return exact, min_v, max_v\n",
    "\n",
    "def validate_min_max(exact, min_v, max_v):\n",
    "    if min_v > 0 or max_v > 0:\n",
    "        exact = 0\n",
    "        if min_v > max_v:\n",
    "            max_v = min_v\n",
    "    speech_grid_interface.set_speaker_numbers(exact, min_v, max_v)\n",
    "    return exact, min_v, max_v\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"SpeechGrid\", theme=gr.themes.Soft()) as gui:\n",
    "\n",
    "    with gr.Tab('Main'):\n",
    "\n",
    "        record_audio = gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\")\n",
    "    \n",
    "        tasks = gr.CheckboxGroup(choices=[(\"Speech to Text\",\"ASR\"),\n",
    "                                          (\"Speaker Separation\",\"SD\"),\n",
    "                                          (\"Speech Detection\",\"VAD\")],\n",
    "                                 value=speech_grid_interface.get_tasks(),\n",
    "                                 label=\"Tasks\",\n",
    "                                 info=\"Apply the following tasks:\")\n",
    "        tasks.input(speech_grid_interface.set_tasks, inputs=tasks)\n",
    "            \n",
    "    \n",
    "        process = gr.Button(\"Process Audio\")\n",
    "    \n",
    "        output_text = gr.Textbox(label='Progress', interactive=False)\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                d1 = gr.DownloadButton(\"Download output\", visible=False)\n",
    "            with gr.Column():\n",
    "                d2 = gr.DownloadButton(\"Download speech file\", visible=False)\n",
    "    \n",
    "        \n",
    "        \n",
    "    with gr.Tab('Advanced Options'):\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ### Speaker Separation\n",
    "            Number of speakers\n",
    "            \"\"\")\n",
    "        with gr.Row():\n",
    "            n_exact = gr.Number(label='Exact')\n",
    "            n_min = gr.Number(label='Minimum')\n",
    "            n_max = gr.Number(label='Maximum')\n",
    "\n",
    "            n_exact.input(reset_min_max,\n",
    "                           inputs=[n_exact, n_min, n_max],\n",
    "                          outputs=[n_exact, n_min, n_max])\n",
    "            n_min.input(validate_min_max,\n",
    "                        inputs=[n_exact, n_min, n_max],\n",
    "                        outputs=[n_exact, n_min, n_max])\n",
    "            n_max.input(validate_min_max,\n",
    "                        inputs=[n_exact, n_min, n_max],\n",
    "                        outputs=[n_exact, n_min, n_max])\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ### Speech to Text\n",
    "            \"\"\"\n",
    "        )\n",
    "        with gr.Row():\n",
    "            avail_lang = [(k,v) for k,v in speech_grid_interface.get_asr_available_lang().items()]\n",
    "            lang_drop = gr.Dropdown(label='Language', choices=avail_lang, value=speech_grid_interface.get_asr_lang())\n",
    "            lang_drop.change(speech_grid_interface.set_asr_lang,\n",
    "                            inputs=lang_drop)\n",
    "\n",
    "            is_lm_enabled = speech_grid_interface.get_lm_enable()\n",
    "            lm_enable = gr.Checkbox(label='Enable Language Model', value=is_lm_enabled, interactive=True)\n",
    "            lm_enable.change(speech_grid_interface.set_lm_enable,\n",
    "                            inputs=lm_enable)\n",
    "    \n",
    "    process.click(speech_grid_interface.process, \n",
    "                      inputs=record_audio,\n",
    "                      outputs=[output_text, d1, d2])\n",
    "     \n",
    "gui.launch(share=shareable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56974ad9-905c-49cd-88bc-5eba96766e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid_interface.speech_grid.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68449419-2953-40f1-b84d-3b0b7e78d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_grid.get_lm_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d740903-bae1-406e-807f-a413d1623656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asr(params=None):\n",
    "    #TODO add to the asr class to read parameters and load the correct model? or a separate function\n",
    "\n",
    "    try:\n",
    "        asr_engine = wav2vec_asr.speech_recognition(ASR_MODEL, device= device, lm_model_path=LM_PATH) #This from parameters and has default one #If language not determine use language id\n",
    "    except:\n",
    "        print(f'Error loading asr model {ASR_MODEL}')\n",
    "        raise \"Error in loading asr model\"\n",
    "    \n",
    "    return asr_engine\n",
    "\n",
    "\n",
    "\n",
    "def load_sd(params=None):\n",
    "    \n",
    "    try:\n",
    "        diarizer = pyannote_sd.speaker_diar(device=device)\n",
    "    except Exception as e:\n",
    "        print(f'Error loading speaker diarization model')\n",
    "        raise f\"Error in loading speaker diarization model {e}\"\n",
    "    \n",
    "    return diarizer\n",
    "\n",
    "\n",
    "\n",
    "vad_params = {\n",
    "             'min_duration_off': 0.09791355693027545,\n",
    "             'min_duration_on': 0.05537587440407595\n",
    "             }\n",
    "\n",
    "def load_vad(params=None):\n",
    "    model_path = 'Models/VAD/pytorch_model.bin'\n",
    "    try:\n",
    "        vad_pipeline = pyannote_vad.speech_detection(model_path, params)\n",
    "    except:\n",
    "        print(f'Error loading voice activity detection model {model_path}')\n",
    "        raise \"Error in loading voice activity detection model\"   \n",
    "    return vad_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209d23b-a26b-4d69-9404-ff4096db0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(speech_file, tasks=['SD', 'ASR'], parameters=None, progress=gr.Progress()):\n",
    "    basename = generate_file_basename()\n",
    "    \n",
    "    speech, sr, duration = load_speech_file(speech_file)\n",
    "    \n",
    "    #This save a version of the speech file with 16k, mono, 16bit\n",
    "    speech_file = join(output_dir,f'{basename}.wav')\n",
    "    sf.write(speech_file, speech, sr)\n",
    "    \n",
    "    tasks = set(tasks)\n",
    "    \n",
    "    task_pipeline = []\n",
    "    if len(tasks) == 1:\n",
    "        if 'ASR' in tasks and duration > MAX_DUR: #Add VAD task to split the speech file by sil\n",
    "            task_pipeline = ['VAD', 'ASR']\n",
    "        else:\n",
    "            task_pipeline = list(tasks)\n",
    "    elif set(tasks) == set(['SD', 'ASR']):\n",
    "        task_pipeline = ['SD', 'ASR']\n",
    "    elif set(tasks) == set(['VAD', 'ASR']):\n",
    "        task_pipeline = ['VAD', 'ASR']\n",
    "    elif set(tasks) == set(['VAD', 'ASR', 'SD']): #If both SD, VAD and ASR then ASR will be applied on SD output\n",
    "        task_pipeline = ['VAD', 'SD', 'ASR']\n",
    "    else:\n",
    "        task_pipeline = tasks #Only 'SD' and 'VAD' each one will be applied separetly\n",
    "\n",
    "    #print(speech_file, tasks, duration)\n",
    "    if 'ASR' in task_pipeline:\n",
    "        asr_engine = load_asr()\n",
    "    \n",
    "    if 'SD' in task_pipeline:\n",
    "        diarizer = load_sd()\n",
    "        \n",
    "    if 'VAD' in task_pipeline:\n",
    "        vad_engine = load_vad(params=vad_params)\n",
    "    \n",
    "    out_textgrid = []\n",
    "    \n",
    "    i = 0\n",
    "    for task in task_pipeline:\n",
    "        progress(i/(len(task_pipeline)+1), desc=f\"Applying {task}\")\n",
    "        i = i+1\n",
    "        if task == 'ASR':\n",
    "            texgrid_file = join(output_dir,f'{basename}_ASR.TextGrid')\n",
    "            if not out_textgrid:\n",
    "                dTiers_asr = asr_engine.process_speech(speech)\n",
    "            else:\n",
    "                input_textgrid = out_textgrid[-1]\n",
    "                dTiers_asr = asr_engine.process_intervals(speech, input_textgrid, sr = sr, offset_sec=0, speech_label = SPEECH_LABEL)\n",
    "            \n",
    "            tm.WriteTxtGrdFromDict(texgrid_file,dTiers_asr,0,duration)\n",
    "            out_textgrid.append(texgrid_file)\n",
    "        \n",
    "        elif task == 'VAD':\n",
    "            rttm_file = join(output_dir,f'{basename}_VAD.rttm')\n",
    "            texgrid_file = join(output_dir,f'{basename}_VAD.TextGrid')\n",
    "            vad_engine.DoVAD(speech,sr)\n",
    "            vad_engine.write_rttm(rttm_file)\n",
    "            vad_engine.write_textgrid(texgrid_file, speech_label=SPEECH_LABEL)\n",
    "            out_textgrid.append(texgrid_file)\n",
    "        \n",
    "        elif task == 'SD':\n",
    "            rttm_file = join(output_dir,f'{basename}_SD.rttm')\n",
    "            texgrid_file = join(output_dir,f'{basename}_SD.TextGrid')\n",
    "            diarizer.diarize(speech=speech, sr=sr)\n",
    "            diarizer.write_rttm(rttm_file)\n",
    "            diarizer.write_textgrid(texgrid_file, speech_label=SPEECH_LABEL)\n",
    "            out_textgrid.append(texgrid_file)\n",
    "    \n",
    "    \n",
    "    output_zip_file = join(output_dir,f'{basename}_output.zip')\n",
    "    \n",
    "    progress(len(task_pipeline)/(len(task_pipeline)+1), desc=f\"Create output archive\")\n",
    "    p = zip_files(out_textgrid, output_zip_file)\n",
    "    \n",
    "    progress(1, desc=p)\n",
    "    \n",
    "    return [p, gr.DownloadButton(label=f\"Download output file\", value=output_zip_file, visible=True), \n",
    "           gr.DownloadButton(label=f\"Download speech file\", value=speech_file, visible=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f9b4b-b383-4360-b53a-59ad148fc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Progress bar\n",
    "#TODO: VAD ########DONE\n",
    "#TODO: Number of speakers\n",
    "#TODO: Word alignment\n",
    "#TODO: Download button  ######DONE\n",
    "#TODO: Wrape in a docker #####DONE\n",
    "#TODO: Test pyannote offline  ########DONE\n",
    "#TODO: Logging of errors and info\n",
    "#TODO: ASR with LM  ########DONE\n",
    "#TODO: Process batch\n",
    "#TODO: Kaldi ASR\n",
    "#TODO: MMS ASR\n",
    "#TODO: Parameters for ASR (hotwords, LM/noLM)\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as gui:\n",
    "\n",
    "    record_audio = gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\")\n",
    "\n",
    "    tasks = gr.CheckboxGroup(choices=[(\"Speech to Text\",\"ASR\"), (\"Speaker Separation\",\"SD\"),(\"Speech Detection\",\"VAD\")], label=\"Tasks\", info=\"Apply the following tasks:\")\n",
    "\n",
    "    process = gr.Button(\"Process Audio\")\n",
    "\n",
    "    output_text = gr.Textbox(label='Progress', interactive=False)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            d1 = gr.DownloadButton(\"Download output\", visible=False)\n",
    "        with gr.Column():\n",
    "            d2 = gr.DownloadButton(\"Download speech file\", visible=False)\n",
    "\n",
    "    process.click(process_file, inputs=[record_audio, tasks], outputs=[output_text, d1, d2])\n",
    "    \n",
    "    \n",
    "     \n",
    "gui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa340a2f-2180-41ce-98f9-f71208923baf",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f46b86-47e2-4d0d-8b17-5661f15ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca648c-2cd1-4ebc-8e6e-b18c707b0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e8c37-7453-49a7-a469-32cb22cabb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25c4c9-589a-4c4f-a721-b4ccf8d8fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained('Models/ASR/mms-1b-all/')\n",
    "processor = AutoProcessor.from_pretrained('Models/ASR/mms-1b-all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd3ca0-e3a6-49ca-9cad-8fad9aa5a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_adapter(target_lang='eng', local_files_only=True)\n",
    "processor.tokenizer.set_target_lang(\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b26577-8375-4997-aac1-1c2b0917a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"facebook/mms-1b-all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc9a34-d1aa-4440-b792-f04f4a5f40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64e313-0022-495b-bcb8-760342118ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6579859-7634-4859-8bea-74d2e5f66656",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('temp_mms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b040cd-61b9-4915-bc0e-5a28a183f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6df7d-60bf-494a-90b7-2fc6550d7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained('temp_mms/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c82be-08be-4ea2-9b30-02cf06c9d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.set_target_lang(\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93936c7-5f55-40c1-966e-35c2acbbedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_adapter(\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616fafb-fb59-412a-bcda-3812ceb11dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained('Models/ASR/wav2vec2-large-xlsr-53-english/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0087de8-b126-4ff8-9a15-7cd3749c3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained('Models/ASR/wav2vec2-large-xlsr-53-english/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5b89f-5d1b-4263-8424-9380fdac30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils import load_speech_file\n",
    "speech, sr, duration = load_speech_file('output/file_7928_20241008_101915.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057d9d1-50d2-4f2a-b5e1-d1b2261f8db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47633af0-b2a8-4f37-9a46-767b0627d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(speech, sampling_rate=16_000, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e411cf6-8cb9-4ebe-a7b6-f1ebe757c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d2a9d-290a-4994-a5a6-622c2c91a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.argmax(outputs, dim=-1)[0]\n",
    "transcription = processor.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46764fef-323f-4fe0-8876-0a0745e4fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1aa54-b2ba-45bb-addd-c66b8a2ee95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6a22d-8703-4f42-b93c-0273caa07ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3df27-4ad7-489d-8a94-9b988e0ea6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=speech, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbdfd6-c8b6-4640-8524-ade4e8799a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyctcdecode==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eaac5b-01a9-4182-a450-210e26a73271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "import pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e9c64-6f1e-44fe-8a2a-2719121eec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ad489-4f17-402c-98ca-76b0c0093043",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_path = 'Models/ASR/LM/ngram/4gram_small.arpa.gz'\n",
    "lm_path_unzip = 'Models/ASR/LM/ngram/4gram_small.arpa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48b5e4-0686-42db-aa60-d11e197c74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os, shutil\n",
    "with gzip.open(lm_path, 'rb') as f_zipped:\n",
    "    with open(lm_path_unzip, 'wb') as f_unzipped:\n",
    "        shutil.copyfileobj(f_zipped, f_unzipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d703ce-28d6-4e73-b15a-c7d7bebbfa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad625132-d403-4a60-9755-75dc9ec662c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525eca5b-152d-465f-b890-aef50ebb1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "decoder = build_ctcdecoder(\n",
    "    labels=list(sorted_vocab_dict.keys()),\n",
    "    kenlm_model_path=lm_path_unzip,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5d55a-4167-4c9b-a775-d48bd9fc5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = decoder.decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bd3af-d0d5-4f00-bec2-69ac69e731b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_lm_path = '3-gram.pruned.1e-7.arpa'\n",
    "if not os.path.exists(uppercase_lm_path):\n",
    "    with gzip.open(lm_gzip_path, 'rb') as f_zipped:\n",
    "        with open(uppercase_lm_path, 'wb') as f_unzipped:\n",
    "            shutil.copyfileobj(f_zipped, f_unzipped)\n",
    "    print('Unzipped the 3-gram language model.')\n",
    "else:\n",
    "    print('Unzipped .arpa already exists.')\n",
    "\n",
    "lm_path = 'lowercase_3-gram.pruned.1e-7.arpa'\n",
    "if not os.path.exists(lm_path):\n",
    "    with open(uppercase_lm_path, 'r') as f_upper:\n",
    "        with open(lm_path, 'w') as f_lower:\n",
    "            for line in f_upper:\n",
    "                f_lower.write(line.lower())\n",
    "print('Converted language model file to lowercase.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269073b-b23a-4cff-9522-24628777fe08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9bdd96-87b4-4e60-86a0-fda1d47bea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d1b5d-532e-44cb-8431-89f10ad67b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'Models/ASR/wav2vec2-large-xlsr-53-english/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ff6eb-c0dd-4a60-88c0-3e9539c2beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b2a67-c392-4037-a23b-ee85c38f19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils import generate_file_basename, load_speech_file, zip_files\n",
    "from pyctcdecode import build_ctcdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248400f-839f-4688-89f8-f578e40ab3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dab9a-d96d-48ee-b1e0-0dcebe2ee69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_path = 'Models/ASR/LM/ngram/4gram_big.arpa.gz'\n",
    "lm_path_unzip = 'Models/ASR/LM/ngram/4gram_big.arpa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4948b75-f308-42ea-bb1d-3df17e57e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os, shutil\n",
    "with gzip.open(lm_path, 'rb') as f_zipped:\n",
    "    with open(lm_path_unzip, 'wb') as f_unzipped:\n",
    "        shutil.copyfileobj(f_zipped, f_unzipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f45624-bd37-458d-800e-ca7e8da39c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "#TODO: Create .bin LM\n",
    "\n",
    "decoder = build_ctcdecoder(\n",
    "    labels=list(sorted_vocab_dict.keys()),\n",
    "    kenlm_model_path=lm_path_unzip,  # either .arpa or .bin file\n",
    "     alpha=0.5,  # tuned on a val set\n",
    "    beta=1.0,  # tuned on a val set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ab167-5d46-4e0c-8320-ee79fe310426",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, sr, duration = load_speech_file('../tmp/file_6820_20240928_232234_530279.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b75227-19d1-4dd9-b1ac-891c5dd03f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(speech, sampling_rate=16_000, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781e695-8ea9-4a4d-8c5a-57a45851a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7db79-f5e7-40f1-9c5a-be2fab4e94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2340a0-d635-4479-aaff-396a5100ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745e941-66c4-45d8-8ed0-e6874a078a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = logits.squeeze()\n",
    "x = x.cpu().detach().numpy()\n",
    "hotwords = None #[\"hello\", \"second\"]\n",
    "text = decoder.decode(x,\n",
    "                     hotwords=hotwords,\n",
    "                     hotword_weight=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d2d99-0fb8-42af-b845-a52ca3b88cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71169338-a564-49c5-b301-0eca272e53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ee529-57ad-4ca7-8fcb-f4b53bb1c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = logits.squeeze()\n",
    "x = x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7609f5-5fa2-4852-a960-b82f89391b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c3322-e9f0-4bed-9180-b13231455e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4c546-dd97-4938-9be8-133c1aeff3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b103c54-477e-4f7b-a542-13a498a4f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "\n",
    "kenlm_model = kenlm.Model(lm_path_unzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f0d9d-f4af-481f-9b9b-bc2f42235cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyannote.audio as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d4135-5794-44fe-8c2e-976dcad7c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9175f-4d39-4753-862a-0286cc90e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"{asctime} - {name} - {levelname} - {message}\",\n",
    "    level=logging.DEBUG, style='{'\n",
    ")\n",
    "\n",
    "logging.info(\"This is an informational message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e821997-d75c-4607-bbbd-34328df0c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    u = 8/0;\n",
    "except:\n",
    "    logging.exception(\"Exception...\")\n",
    "    logging.warning(\"Non critical exception ...\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b8f3f-339c-47a5-9cc0-619ae0973d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_function():\n",
    "    logging.debug(\"Debug message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82acf522-233a-4107-9a20-89b2ddded1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab81a3-384f-4d93-a0c2-3ffbe45f0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eeb460-626a-4ad2-aa49-2db98e268aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd21d1-c333-47c6-8319-ca4ecf6dac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = logging.Formatter(\"{asctime} - {levelname}\", style='{')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98ee4e-8ca7-4a38-adeb-91eff76c7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHand = logging.FileHandler('test.log', mode='a', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc01328-f20e-41e7-ae9a-d2c6bfba488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileHand.setFormatter(formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be6ecf-0b6b-4053-8019-b4ac91463b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d126da-ac7a-430e-8ce4-7ce298f094c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c4bf8-e0df-4850-a2fd-a2330348e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.addHandler(fileHand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2fb7c-425e-4574-ae1a-f7a779aa9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Lets see!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab0ae35-358e-4cb0-aac6-0f6636bdce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.getEffectiveLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c0b76-2f90-46f1-b9ba-ea5ccba9b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5d43d-44f7-413e-bc2c-988544de72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d054231-c9eb-4c14-87b7-d82abb3abdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c5b32-0124-4628-bced-999dee42fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc0aa5-0037-4ab8-9a93-58ad6c46882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd5cc8-6ca0-4125-a15a-de509a57425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502a432-d6bf-4cbd-be71-b3ed91e4aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057d647-1681-4364-b52e-e9c6ef05e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.getEffectiveLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313a9f2-dada-4164-b526-212d941ec6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c2e59-96a1-4038-b287-3e86fbfe3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_a = logging.getLogger('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c5ffee-8199-4f49-a5e6-7d8187c83818",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7760d9-4821-4639-8f6c-abe16ff8b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a169b-f55f-4198-ab23-898876fac0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87c8af-a045-46c7-8ce0-0118518cb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f19de7-214d-4a23-ad57-cc4dbce1b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_a.setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef3b74-f24a-4e3e-bbef-38f1682d9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed522b8-c7cb-431e-b1e9-7c8ab4da3e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def reset_min_max(exact,min_v,max_v):\n",
    "  if exact > 0:\n",
    "      min_v = 0\n",
    "      max_v = 0\n",
    "  return exact, min_v, max_v\n",
    "\n",
    "def validate(exact, min_v, max_v):\n",
    "    if min_v > 0 or max_v > 0:\n",
    "        exact = 0\n",
    "        if min_v > max_v:\n",
    "            max_v = min_v\n",
    "    return exact, min_v, max_v\n",
    "  \n",
    "def toggle_it():\n",
    "\n",
    "with gr.Blocks() as gui:\n",
    "    x = gr.Button(visible=True)\n",
    "    a = gr.Number(label='Exact', interactive=True)\n",
    "    b = gr.Number(label='Min', interactive=True)\n",
    "    c = gr.Number(label='Max', interactive=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    a.change(reset_min_max,inputs=[a,b,c],outputs=[a,b,c])\n",
    "    #b.change(reset_exact, inputs=[b,a],outputs=a)\n",
    "    #c.change(reset_exact, inputs=[c,a],outputs=a)\n",
    "    b.change(validate, inputs=[a,b,c], outputs=[a,b,c])\n",
    "    c.change(validate, inputs=[a,b,c], outputs=[a,b,c])\n",
    "\n",
    "\n",
    "gui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa21c0-93f2-409e-8885-3c3ea7c98d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'a':'b','v':'h'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecda0ec-fac3-4bd7-bcde-153a7d125da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'b' in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a6639-a492-47ba-96fb-65c80cbfb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = True\n",
    "T = ['ASR']\n",
    "L = ['ASR','SD']\n",
    "\n",
    "if 'ASR' in T and ('ASR' not in L or f):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de609d54-77dc-48fd-ad52-c3e507a674cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name='f',a='b'):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    name = gr.Textbox(label=\"Name\")\n",
    "    output = gr.Textbox(label=\"Output Box\")\n",
    "    greet_btn = gr.Button(\"Greet\")\n",
    "    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb251e7-3155-4625-9e8a-fe2cdf048ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyClass:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621e986-03b5-414d-87a1-efb35e626ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = EmptyClass()\n",
    "dir(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ea3e5-2e38-415e-9dbe-719e8557d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 100\n",
    "\n",
    "def print_x():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52c093-2862-421b-9305-fc122eb99559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119cad52-dd14-4b78-83d5-d284281a794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/z5173707/root/projects/FHS/venv/python3.12.6/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7582899b-8b03-4810-a8bf-afa0cdfae1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/z5173707/root/projects/FHS/venv/python3.12.6/lib/python3.12/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "\n",
    "\n",
    "    \n",
    "with gr.Blocks() as gui:\n",
    "    f_s = gr.State(x)\n",
    "    x_in = gr.Number()\n",
    "    def change_x(x_in, f):\n",
    "        x = x_in\n",
    "        return f\n",
    "    x_in.input(change_x, inputs=[x_in, f_s], outputs=f_s)\n",
    "\n",
    "gui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c4ee7b-c11f-4a88-a264-befbe25a6d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e44a05-f420-49d3-8d3a-8c8b9672f2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_s.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7140bb-8d43-417d-9212-12f73ede3f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
